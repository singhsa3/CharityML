{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPPayURTaouRH3Omzo5V/ok",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singhsa3/CharityML/blob/master/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "16dOC0nljFI5"
      },
      "outputs": [],
      "source": [
        "# PyTorch libraries and modules\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import GroupNorm, Linear, ReLU, GELU, CrossEntropyLoss, Sequential, Conv2d, Conv1d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Fp32GroupNorm(nn.GroupNorm):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = F.group_norm(\n",
        "            input.float(),\n",
        "            self.num_groups,\n",
        "            self.weight.float() if self.weight is not None else None,\n",
        "            self.bias.float() if self.bias is not None else None,\n",
        "            self.eps,\n",
        "        )\n",
        "        return output.type_as(input)"
      ],
      "metadata": {
        "id": "rZvs_5tYopQS"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "pathG='/content/drive/MyDrive/Pract/data'\n",
        "cp = '/content/drive/MyDrive/Pretrained/wav2vec_small.pt'\n",
        "sample=\"/content/drive/MyDrive/Pract/data/voice_samples/1173_GM1001_1326493712.wav\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfKTRJ9PjNjB",
        "outputId": "01e422ab-2585-4f8c-9358-19363228f994"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(pathG+\"/featuresdict.pickle\", \"rb\") as f:\n",
        "  features=pickle.load(f)"
      ],
      "metadata": {
        "id": "ZYaMFuEBkDds"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(pathG+\"/filenameslist.pickle\", \"rb\") as f:\n",
        "  fnames=pickle.load(f)"
      ],
      "metadata": {
        "id": "oe2ksLT3ksir"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(pathG+\"/labels/Yared Alemu_fear.csv\")\n",
        "df = df[(df['name'].isin (features.keys()))].reset_index()\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cXMRhMAmrxgL",
        "outputId": "4e7f4bd6-2f11-4618-ab63-8d8742f26bbf"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index  Unnamed: 0    therapist                        name emotion_type  \\\n",
              "0      0        8015  Yared Alemu   6708_53113_1589932800.wav         fear   \n",
              "1      1        5925  Yared Alemu   7163_53113_1603843200.wav         fear   \n",
              "2      3        4565  Yared Alemu  52757_53113_1569456000.wav         fear   \n",
              "3      4        4530  Yared Alemu  52757_53113_1574294400.wav         fear   \n",
              "4      5        6625  Yared Alemu   1940_39117_1592956800.wav         fear   \n",
              "\n",
              "   rating  emotion  \n",
              "0    high        1  \n",
              "1    high        1  \n",
              "2  medium        0  \n",
              "3     low        0  \n",
              "4     low        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49fdbe75-490b-4414-9b50-782fe0630cd0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>therapist</th>\n",
              "      <th>name</th>\n",
              "      <th>emotion_type</th>\n",
              "      <th>rating</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>8015</td>\n",
              "      <td>Yared Alemu</td>\n",
              "      <td>6708_53113_1589932800.wav</td>\n",
              "      <td>fear</td>\n",
              "      <td>high</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>5925</td>\n",
              "      <td>Yared Alemu</td>\n",
              "      <td>7163_53113_1603843200.wav</td>\n",
              "      <td>fear</td>\n",
              "      <td>high</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4565</td>\n",
              "      <td>Yared Alemu</td>\n",
              "      <td>52757_53113_1569456000.wav</td>\n",
              "      <td>fear</td>\n",
              "      <td>medium</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4530</td>\n",
              "      <td>Yared Alemu</td>\n",
              "      <td>52757_53113_1574294400.wav</td>\n",
              "      <td>fear</td>\n",
              "      <td>low</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>6625</td>\n",
              "      <td>Yared Alemu</td>\n",
              "      <td>1940_39117_1592956800.wav</td>\n",
              "      <td>fear</td>\n",
              "      <td>low</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49fdbe75-490b-4414-9b50-782fe0630cd0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49fdbe75-490b-4414-9b50-782fe0630cd0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49fdbe75-490b-4414-9b50-782fe0630cd0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=features[df.iloc[0][3]]\n",
        "x= np.pad(x, ((0,0),(10, 7000-x.shape[1])), 'constant')\n",
        "arr =np.expand_dims(x, axis=0)\n",
        "#print(arr.shape)\n",
        "for i,row in df.iterrows():\n",
        "  if i>0:\n",
        "    ft = features[row['name']]\n",
        "    ft= np.pad(ft, ((0,0),(10, 7000-ft.shape[1])), 'constant')\n",
        "    arr2 = np.expand_dims(ft, axis=0)\n",
        "    #print(arr2.shape)\n",
        "    arr = np.vstack((arr,arr2))\n",
        "labels=np.array(df.emotion)"
      ],
      "metadata": {
        "id": "h5VR9_vIobOI"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN_IxsOuwtst",
        "outputId": "bd82624d-fd55-4df2-fc45-e29a29f433a6"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 128, 7010)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_x, val_x, train_y, val_y = train_test_split(arr, labels, test_size = 0.3)"
      ],
      "metadata": {
        "id": "anTlik-XxNjL"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting training images into torch format\n",
        "#train_x = train_x.reshape(train_x.shape[0], 1, train_x.shape[1], train_x.shape[2])\n",
        "train_x  = torch.from_numpy(train_x)\n",
        "\n",
        "# converting the target into torch format\n",
        "train_y = train_y.astype(int);\n",
        "train_y = torch.from_numpy(train_y)\n",
        "\n",
        "# shape of training data\n",
        "train_x.shape, train_y.shape\n",
        "# converting validation images into torch format\n",
        "#val_x = val_x.reshape(val_x.shape[0], 1, val_x.shape[1], val_x.shape[2])\n",
        "val_x  = torch.from_numpy(val_x)\n",
        "\n",
        "# converting the target into torch format\n",
        "val_y = val_y.astype(int);\n",
        "val_y = torch.from_numpy(val_y)\n",
        "\n",
        "# shape of validation data\n",
        "val_x.shape, val_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2Fqwi2YxgfU",
        "outputId": "77a72d58-6d63-4002-84e3-fb0453e62227"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([150, 128, 7010]), torch.Size([150]))"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "!nvidia-smi\n",
        "a = torch.cuda.memory_allocated(0)\n",
        "c = torch.cuda.memory_reserved(0)\n",
        "print(a,c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuxXjoYz2a2l",
        "outputId": "9e39d666-d503-407b-b1d1-78e6bd1ee9b1"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jun  3 03:38:10 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    33W / 250W |  13005MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "9117355520 12626952192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "B10uqsUS2QDr"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(Module):   \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.cnn_layers = Sequential(\n",
        "            # Defining a 2D convolution layer\n",
        "            Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n",
        "            BatchNorm2d(4),\n",
        "            ReLU(inplace=True),\n",
        "            MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Defining another 2D convolution layer\n",
        "            Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
        "            BatchNorm2d(4),\n",
        "            ReLU(inplace=True),\n",
        "            MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.linear_layers = Sequential(\n",
        "            Linear(224256, 10)\n",
        "        )\n",
        "\n",
        "    # Defining the forward pass    \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear_layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "69IIy-kNzPZN"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(Module):   \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.cnn_layers =  Sequential(\n",
        "        Conv1d(128, 512, kernel_size=(10,), stride=(5,), bias=False),\n",
        "        Dropout(p=0.0, inplace=False),\n",
        "        Fp32GroupNorm(512, 512, eps=1e-05, affine=True),\n",
        "        GELU(),\n",
        "     \n",
        "        Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False),\n",
        "        Dropout(p=0.0, inplace=False),\n",
        "        GELU(),\n",
        "      \n",
        "        Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False),\n",
        "        Dropout(p=0.0, inplace=False),\n",
        "        GELU(),\n",
        "       \n",
        "        Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False),\n",
        "        Dropout(p=0.0, inplace=False),\n",
        "        GELU(),\n",
        " \n",
        "   \n",
        "        Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False),\n",
        "        Dropout(p=0.0, inplace=False),\n",
        "        GELU(),\n",
        "      \n",
        "\n",
        "        Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False),\n",
        "        Dropout(p=0.0, inplace=False),\n",
        "        GELU(),\n",
        "    \n",
        "   \n",
        "        Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False),\n",
        "        Dropout(p=0.0, inplace=False),\n",
        "        GELU()\n",
        "      )\n",
        "\n",
        "        self.linear_layers = Sequential(\n",
        "            Linear(10752, 10)\n",
        "        )\n",
        "\n",
        "    # Defining the forward pass    \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear_layers(x)\n",
        "        return x\n",
        "\n",
        "     \n",
        "    \n",
        "  "
      ],
      "metadata": {
        "id": "ZaQxRAfVmJ9S"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the model\n",
        "model = Net()\n",
        "# defining the optimizer\n",
        "optimizer = Adam(model.parameters(), lr=0.07)\n",
        "# defining the loss function\n",
        "criterion = CrossEntropyLoss()\n",
        "# checking if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "    \n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTnHWNC2zR70",
        "outputId": "8ecda90e-bb7c-425f-fa6d-29a4c2d08f3d"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (cnn_layers): Sequential(\n",
            "    (0): Conv1d(128, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
            "    (1): Dropout(p=0.0, inplace=False)\n",
            "    (2): Fp32GroupNorm(128, 512, eps=1e-05, affine=True)\n",
            "    (3): GELU()\n",
            "    (4): Conv1d(128, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
            "    (5): Dropout(p=0.0, inplace=False)\n",
            "    (6): GELU()\n",
            "    (7): Conv1d(128, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
            "    (8): Dropout(p=0.0, inplace=False)\n",
            "    (9): GELU()\n",
            "    (10): Conv1d(128, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
            "    (11): Dropout(p=0.0, inplace=False)\n",
            "    (12): GELU()\n",
            "    (13): Conv1d(128, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
            "    (14): Dropout(p=0.0, inplace=False)\n",
            "    (15): GELU()\n",
            "    (16): Conv1d(128, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
            "    (17): Dropout(p=0.0, inplace=False)\n",
            "    (18): GELU()\n",
            "    (19): Conv1d(128, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
            "    (20): Dropout(p=0.0, inplace=False)\n",
            "    (21): GELU()\n",
            "  )\n",
            "  (linear_layers): Sequential(\n",
            "    (0): Linear(in_features=10752, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    tr_loss = 0\n",
        "    # getting the training set\n",
        "    x_train, y_train = Variable(train_x), Variable(train_y)\n",
        "    # getting the validation set\n",
        "    x_val, y_val = Variable(val_x), Variable(val_y)\n",
        "    # converting the data into GPU format\n",
        "    if torch.cuda.is_available():\n",
        "        x_train = x_train.cuda()\n",
        "        y_train = y_train.cuda()\n",
        "        x_val = x_val.cuda()\n",
        "        y_val = y_val.cuda()\n",
        "\n",
        "    # clearing the Gradients of the model parameters\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # prediction for training and validation set\n",
        "    output_train = model(x_train)\n",
        "    output_val = model(x_val)\n",
        "\n",
        "    # computing the training and validation loss\n",
        "    loss_train = criterion(output_train, y_train)\n",
        "    loss_val = criterion(output_val, y_val)\n",
        "    train_losses.append(loss_train)\n",
        "    val_losses.append(loss_val)\n",
        "\n",
        "    # computing the updated weights of all the model parameters\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "    tr_loss = loss_train.item()\n",
        "    if epoch%2 == 0:\n",
        "        # printing the validation loss\n",
        "        print('Epoch : ',epoch+1, '\\t', 'loss :', loss_val)"
      ],
      "metadata": {
        "id": "bOJxjOfnzWhT"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the batch size and the number of epochs\n",
        "BATCH_SIZE = 10\n",
        "N_EPOCHS = 100\n",
        "torch.cuda.empty_cache()\n",
        "# Use torch.utils.data to create a DataLoader \n",
        "# that will take care of creating batches \n",
        "dataset = TensorDataset(train_x, train_y)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Get the dataset size for printing (it is equal to N_SAMPLES)\n",
        "dataset_size = len(dataloader.dataset)\n",
        "# empty list to store training losses\n",
        "train_losses = [100,100,100,100,100]\n",
        "# empty list to store validation losses\n",
        "val_losses = []\n",
        "\n",
        "# Loop over epochs\n",
        "for epoch in range(N_EPOCHS):\n",
        "    mnl = np.mean(train_losses)\n",
        "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
        "\n",
        "    # Loop over batches in an epoch using DataLoader\n",
        "    for id_batch, (x_batch, y_batch) in enumerate(dataloader):\n",
        "      if torch.cuda.is_available():\n",
        "        x_batch = x_batch.cuda()\n",
        "        y_batch = y_batch.cuda()\n",
        "        #x_val = val_x.cuda()\n",
        "        #y_val = val_y.cuda()\n",
        "\n",
        "        y_batch_pred = model(x_batch)\n",
        "        #output_val = model(x_val)\n",
        "\n",
        "        loss = criterion(y_batch_pred, y_batch)\n",
        "        #loss_val = criterion(output_val, y_val)\n",
        "        #train_losses.append(loss)\n",
        "        #val_losses.append(loss_val)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Every 100 batches, print the loss for this batch\n",
        "        # as well as the number of examples processed so far \n",
        "        if id_batch % 100 == 0:\n",
        "            loss, current = loss.item(), (id_batch + 1)* len(x_batch)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{dataset_size:>5d}]\")    \n",
        "    train_losses.pop()\n",
        "    train_losses.insert(0,loss.detach().cpu().numpy())\n",
        "    #if np.mean(train_losses)>mnl*1.10:\n",
        "      #break\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "E0K3r2faEGAf",
        "outputId": "1e877dc2-3679-4a1f-c73c-433a9193d02c"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-163-ea40d99d9116>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#y_val = val_y.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0my_batch_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;31m#output_val = model(x_val)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-161-1826a7af8635>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Defining the forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    297\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    298\u001b[0m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0;32m--> 299\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [512, 128, 3], expected input[10, 512, 1401] to have 128 channels, but got 512 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction for training set\n",
        "with torch.no_grad():\n",
        "    output = model(train_x.cuda())\n",
        "    \n",
        "softmax = torch.exp(output).cpu()\n",
        "prob = list(softmax.numpy())\n",
        "predictions = np.argmax(prob, axis=1)\n",
        "\n",
        "# accuracy on training set\n",
        "accuracy_score(train_y, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRFLwJxUqhnd",
        "outputId": "23b3a397-b2e9-4c9e-c11d-77d2085614a3"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5171428571428571"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# prediction for validation set\n",
        "with torch.no_grad():\n",
        "    output = model(val_x.cuda())\n",
        "\n",
        "softmax = torch.exp(output).cpu()\n",
        "prob = list(softmax.numpy())\n",
        "predictions = np.argmax(prob, axis=1)\n",
        "\n",
        "# accuracy on validation set\n",
        "accuracy_score(val_y, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3MFC8yELtJQ",
        "outputId": "b00ee407-ac6a-49de-c84c-dc6b6813b08a"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    }
  ]
}